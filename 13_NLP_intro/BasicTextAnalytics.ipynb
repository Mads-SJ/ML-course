{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "F5HSiEcYLQ0F"
      },
      "outputs": [],
      "source": [
        "# Basic text analytics.\n",
        "# Sila 18 November 2022\n",
        "#\n",
        "# From \"Blueprints for Text Analytics by Albrecht, Ramachandran & Winkler\"\n",
        "# and\n",
        "# Using Gensim for Text similiarity scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "s7-BGyBfMAWN"
      },
      "outputs": [],
      "source": [
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "6uQYYnroMYDc"
      },
      "outputs": [],
      "source": [
        "text = \"\"\"\n",
        "2019-08-10 23:32: @pete/@louis - I don't have a well-designed \n",
        "solution for today's problem. The code of module AC68 should be -1. \n",
        "Have to think a bit... #goodnight ;-) ðŸ˜©ðŸ˜¬\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JIRadQBhMy7n",
        "outputId": "dfb75748-0bfd-48b3-a29f-5c3e260cf895"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2019|08|10|23|32|pete|louis|don|have|well|designed|solution|for|today|problem|The|code|of|module|AC68|should|be|Have|to|think|bit|goodnight\n"
          ]
        }
      ],
      "source": [
        "tokens = re.findall(r'\\w\\w+', text)\n",
        "print(*tokens, sep='|')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7GN114UM4Cs",
        "outputId": "2bd6df23-4a5e-499e-83f2-cf7df7325372"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2019-08-10|23:32|@pete|@louis|I|don't|have|a|well-designed|solution|for|today's|problem|The|code|of|module|AC68|should|be|-1|Have|to|think|a|bit|#goodnight|;-)|ðŸ˜©|ðŸ˜¬\n"
          ]
        }
      ],
      "source": [
        "RE_TOKEN = re.compile(r\"\"\"\n",
        "               ( [#]?[@\\w'â€™\\.\\-\\:]*\\w     # words, hash tags and email adresses\n",
        "               | [:;<]\\-?[\\)\\(3]          # coarse pattern for basic text emojis\n",
        "               | [\\U0001F100-\\U0001FFFF]  # coarse code range for unicode emojis\n",
        "               )\n",
        "               \"\"\", re.VERBOSE)\n",
        "\n",
        "def tokenize(text):\n",
        "    return RE_TOKEN.findall(text)\n",
        "\n",
        "tokens = tokenize(text)\n",
        "print(*tokens, sep='|')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zjHoFyTZNBu6",
        "outputId": "080facb7-b7a7-49e0-9736-a1711e3e1385"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2019-08-10|23:32|:|@|pete/|@|louis|-|I|do|n't|have|a|well-designed|solution|for|today|'s|problem|.|The|code|of|module|AC68|should|be|-1|.|Have|to|think|a|bit|...|#|goodnight|;|-|)|ðŸ˜©ðŸ˜¬\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\Mads\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "\n",
        "nltk.download('punkt') ###\n",
        "tokens = nltk.tokenize.word_tokenize(text)\n",
        "print(*tokens, sep='|')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Gn_nF42hNKRA"
      },
      "outputs": [],
      "source": [
        "# With SpaCy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "mEoLtAp_NYk-"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "nlp = spacy.load('en_core_web_md')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "_HotGqJHNcjw"
      },
      "outputs": [],
      "source": [
        "text = \"My best friend Ryan Peters likes fancy adventure games.\"\n",
        "doc = nlp(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "liFtqO0ZNr0f",
        "outputId": "09509b8a-8c28-4c28-eb99-37976f17696b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "My|best|friend|Ryan|Peters|likes|fancy|adventure|games|.|"
          ]
        }
      ],
      "source": [
        "for token in doc:\n",
        "    print(token, end=\"|\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "H5pKkQ5hN0Ab"
      },
      "outputs": [],
      "source": [
        "# Stop words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZAx3dtomN2HV",
        "outputId": "8587ed8c-4107-49ba-e46a-48accbc64151"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Dear, Ryan, need, sit, talk, Regards, Pete]\n"
          ]
        }
      ],
      "source": [
        "text = \"Dear Ryan, we need to sit down and talk. Regards, Pete\"\n",
        "doc = nlp(text)\n",
        "\n",
        "non_stop = [t for t in doc if not t.is_stop and not t.is_punct]\n",
        "print(non_stop)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "a6mdywneOGco"
      },
      "outputs": [],
      "source": [
        "# Lemmas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n5sW_C37OJEZ",
        "outputId": "23a13d83-8011-4608-cc80-f5527d8f2102"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dear|Ryan|,|we|need|to|sit|down|and|talk|.|regard|,|Pete\n"
          ]
        }
      ],
      "source": [
        "print(*[t.lemma_ for t in doc], sep='|')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "rx5D-_XcOM0h"
      },
      "outputs": [],
      "source": [
        "# Extracting Named Entities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AN_TA3kiOfFc",
        "outputId": "0c44fb2e-07b5-4133-c5b9-9bb43312d1ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(James O'Neill, PERSON) (World Cargo Inc, ORG) (San Francisco, GPE) "
          ]
        }
      ],
      "source": [
        "text = \"James O'Neill, chairman of World Cargo Inc, lives in San Francisco.\"\n",
        "doc = nlp(text)\n",
        "\n",
        "for ent in doc.ents:\n",
        "    print(f\"({ent.text}, {ent.label_})\", end=\" \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "hUiVwI8iPP_C"
      },
      "outputs": [],
      "source": [
        "# Using Gensim to make Predictions.\n",
        "#\n",
        "# Text similiarity scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "EqxCLGjObAD2"
      },
      "outputs": [],
      "source": [
        "from gensim import corpora, models, similarities\n",
        "import jieba"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "-kJdpQ1WbMbu"
      },
      "outputs": [],
      "source": [
        "texts = ['I love reading Japanese novels. My favorite Japanese writer is Tanizaki Junichiro.',\n",
        "         'Natsume Soseki is a well-known Japanese novelist and his Kokoro is a masterpiece.',\n",
        "         'American modern poetry is good. ']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "rJ9PnsJ6bcWG"
      },
      "outputs": [],
      "source": [
        "keyword = 'Japan has some great novelists. Who is your favorite Japanese writer?'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "PlfmvRCNeyVU"
      },
      "outputs": [],
      "source": [
        "# jieba is a text segmentation Python module for cutting the words \n",
        "# into segmentations for easier analysis of text similarity in the future.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "p1RmKn5ibeAc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Building prefix dict from the default dictionary ...\n",
            "Dumping model to file cache C:\\Users\\Mads\\AppData\\Local\\Temp\\jieba.cache\n",
            "Loading model cost 1.508 seconds.\n",
            "Prefix dict has been built successfully.\n"
          ]
        }
      ],
      "source": [
        "texts = [jieba.lcut(text) for text in texts]\n",
        "dictionary = corpora.Dictionary(texts)\n",
        "feature_cnt = len(dictionary.token2id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "PD1LMTcibyxD"
      },
      "outputs": [],
      "source": [
        "corpus = [dictionary.doc2bow(text) for text in texts]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "Dl7Sjhshb4bL"
      },
      "outputs": [],
      "source": [
        "tfidf = models.TfidfModel(corpus) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "KJNUqAhhb-85"
      },
      "outputs": [],
      "source": [
        "kw_vector = dictionary.doc2bow(jieba.lcut(keyword))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "BdgHbleJcDZG"
      },
      "outputs": [],
      "source": [
        "index = similarities.SparseMatrixSimilarity(tfidf[corpus], num_features = feature_cnt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "xQfSSI44cHlE"
      },
      "outputs": [],
      "source": [
        "sim = index[tfidf[kw_vector]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HSVtzkCQcMCQ",
        "outputId": "bd8f5cce-753e-43cc-a86b-623f420ffa59"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "keyword is similar to text1: 0.50\n",
            "keyword is similar to text2: 0.02\n",
            "keyword is similar to text3: 0.00\n"
          ]
        }
      ],
      "source": [
        "for i in range(len(sim)):\n",
        "    print('keyword is similar to text%d: %.2f' % (i + 1, sim[i]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "_6l47SW_gWT-"
      },
      "outputs": [],
      "source": [
        "texts = ['Du er uddannet i kommunikation', \n",
        "'Du har mindst 3 Ã¥rs erfaring med e-mailmarketing fra et reklamebureau eller en stÃ¸rre virksomhed', \n",
        "'Du er vant til at analysere resultaterne af din egen markedsfÃ¸ringsindsats']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "vW_a8Zzrg1Ah"
      },
      "outputs": [],
      "source": [
        "keyword = 'Analyse af markedsfÃ¸rings resultater er lige dig'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "kBU7NARmhE6z"
      },
      "outputs": [],
      "source": [
        "texts = [jieba.lcut(text) for text in texts]\n",
        "dictionary = corpora.Dictionary(texts)\n",
        "feature_cnt = len(dictionary.token2id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "JTobL29rhIZr"
      },
      "outputs": [],
      "source": [
        "corpus = [dictionary.doc2bow(text) for text in texts]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "wAfRNOhehNQz"
      },
      "outputs": [],
      "source": [
        "tfidf = models.TfidfModel(corpus) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "bGWUYLkHhROe"
      },
      "outputs": [],
      "source": [
        "kw_vector = dictionary.doc2bow(jieba.lcut(keyword))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "NL67in9UhW2I"
      },
      "outputs": [],
      "source": [
        "index = similarities.SparseMatrixSimilarity(tfidf[corpus], num_features = feature_cnt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "l9kgoU0_haYZ"
      },
      "outputs": [],
      "source": [
        "sim = index[tfidf[kw_vector]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BGQ1bU7Vhd6O",
        "outputId": "67433afa-eba7-4dcc-e9c6-5f03bae3fec3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "keyword is similar to text1: 0.05\n",
            "keyword is similar to text2: 0.02\n",
            "keyword is similar to text3: 0.47\n"
          ]
        }
      ],
      "source": [
        "for i in range(len(sim)):\n",
        "    print('keyword is similar to text%d: %.2f' % (i + 1, sim[i]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "wK2ianYujAiO"
      },
      "outputs": [],
      "source": [
        "texts = ['Du er god til konstruktion af modeller', \n",
        "'Er vant til at arbejde selvstÃ¦ndigt og med passion', \n",
        "'Du beskriver dig selv som en der er vant til at knokle og give alt for teamet']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "j4bDcrXkjYmg"
      },
      "outputs": [],
      "source": [
        "keyword = 'Er vant til at knokle for teamet'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "b9WiFeCyjiGU"
      },
      "outputs": [],
      "source": [
        "texts = [jieba.lcut(text) for text in texts]\n",
        "dictionary = corpora.Dictionary(texts)\n",
        "feature_cnt = len(dictionary.token2id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "gfvEKSzkjlU5"
      },
      "outputs": [],
      "source": [
        "corpus = [dictionary.doc2bow(text) for text in texts]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "pXPrWXV8jn8L"
      },
      "outputs": [],
      "source": [
        "tfidf = models.TfidfModel(corpus) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "LLNOtKM5jpy6"
      },
      "outputs": [],
      "source": [
        "kw_vector = dictionary.doc2bow(jieba.lcut(keyword))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "cof8DC50ju37"
      },
      "outputs": [],
      "source": [
        "index = similarities.SparseMatrixSimilarity(tfidf[corpus], num_features = feature_cnt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "MAeWtaJQjx_Z"
      },
      "outputs": [],
      "source": [
        "sim = index[tfidf[kw_vector]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gVrhvNJ3j1YE",
        "outputId": "80a6d607-b273-4a7d-8086-5fa6927907ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "keyword is similar to text1: 0.00\n",
            "keyword is similar to text2: 0.23\n",
            "keyword is similar to text3: 0.46\n"
          ]
        }
      ],
      "source": [
        "for i in range(len(sim)):\n",
        "    print('keyword is similar to text%d: %.2f' % (i + 1, sim[i]))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
